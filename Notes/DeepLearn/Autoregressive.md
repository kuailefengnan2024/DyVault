
---

### 1. 自回归模型 (Autoregressive Model) 流程
**任务**: 生成文本，预测下一个词。  
**示例输入**: “我喜欢”  
**目标**: 预测下一个词，例如 “听”。

---

#### 1.1 分词与嵌入层 (Tokenization & Embedding)
**操作**: 将输入句子分词并映射为词嵌入向量。  
- 假设词汇表大小为 1000，嵌入维度为 256。  
- 分词结果: ["我", "喜欢"]。  
- 输入维度: [2]（2 个词）。  
- 输出维度: [2, 256]（每个词映射为 256 维嵌入向量）。  
```
  输入: ["我", "喜欢"]
  输出: tensor([
    [0.23, -0.45, 0.67, ..., 0.89],  # "我" 的嵌入
    [0.56, 0.12, -0.78, ..., 0.34]   # "喜欢" 的嵌入
  ])（形状: [2, 256]，假设的词嵌入值）
```

---

#### 1.2 位置编码 (Positional Encoding)
**操作**: 为每个词添加位置信息。  
- 输入维度: [2, 256]。  
- 输出维度: [2, 256]（词嵌入 + 位置编码）。  
```
  输入: tensor([
    [0.23, -0.45, 0.67, ..., 0.89],
    [0.56, 0.12, -0.78, ..., 0.34]
  ])
  位置编码: tensor([
    [0.00, 1.00, 0.00, ..., 0.99],  # 位置 0
    [0.84, 0.54, 0.01, ..., 0.98]   # 位置 1
  ])（假设的正弦/余弦值）
  输出: tensor([
    [0.23, 0.55, 0.67, ..., 1.88],
    [1.40, 0.66, -0.77, ..., 1.32]
  ])（词嵌入 + 位置编码）
```

---

#### 1.3 自回归注意力层 (Causal Self-Attention)
**操作**: 使用因果掩码（只允许关注之前的词），计算自注意力。  
- 假设使用单头注意力，维度保持 256。  
- 输入维度: [2, 256]。  
- 输出维度: [2, 256]。  
```
  输入: tensor([
    [0.23, 0.55, 0.67, ..., 1.88],
    [1.40, 0.66, -0.77, ..., 1.32]
  ])
  注意力掩码: [[1, 0], [1, 1]]（"我" 只看自己，"喜欢" 看 "我" 和自己）
  注意力分数（简化假设）: tensor([
    [1.0],           # "我" 只关注自己
    [0.4, 0.6]       # "喜欢" 关注 "我" 和自己
  ])
  输出: tensor([
    [0.23, 0.55, 0.67, ..., 1.88],  # "我" 的表示不变
    [0.85, 0.61, -0.25, ..., 1.50]  # "喜欢" 的加权表示
  ])（形状: [2, 256]）
```

---

#### 1.4 前馈神经网络层 (Feed-Forward Network)
**操作**: 每个位置独立应用全连接层，ReLU 激活。  
- 内部维度扩展到 1024，再压缩回 256。  
- 输入维度: [2, 256]。  
- 输出维度: [2, 256]。  
```
  输入: tensor([
    [0.23, 0.55, 0.67, ..., 1.88],
    [0.85, 0.61, -0.25, ..., 1.50]
  ])
  输出: tensor([
    [0.30, 0.60, 0.70, ..., 1.95],
    [0.90, 0.65, 0.00, ..., 1.60]
  ])（假设前馈网络计算并激活后的结果）
```

---

#### 1.5 输出层 (Linear + Softmax)
**操作**: 取最后一个词的表示，映射到词汇表大小，预测下一个词。  
- 输入维度: [256]（"喜欢" 的表示）。  
- 输出维度: [1000]（词汇表大小）。  
```
  输入: tensor([0.90, 0.65, 0.00, ..., 1.60])（"喜欢" 的 256 维表示）
  输出（线性变换后）: tensor([1.5, -0.2, 2.3, ..., 0.8])（1000 维 logits）
  Softmax 概率: tensor([0.10, 0.02, 0.35, ..., 0.05])（假设词汇表中词的概率）
  预测词: "听"（假设概率最高）
```

---

#### 自回归生成
**操作**: 将预测的词 "听" 添加到序列中，重复上述步骤生成更多词。  
- 新输入: ["我", "喜欢", "听"] → 继续预测下一个词。
